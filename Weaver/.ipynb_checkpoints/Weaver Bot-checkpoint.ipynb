{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b4b126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6df3168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in valid words\n",
    "df = pd.read_csv('Collins Scrabble Words (2019).txt', sep=' ', header=None)\n",
    "df = df.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a505194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5379\n"
     ]
    }
   ],
   "source": [
    "#Remove words that are not valid in the game\n",
    "words = []\n",
    "for word in df[0]:\n",
    "    if ((len(word)) == 4):\n",
    "        words.append(word)\n",
    "rem = [\"HOND\", \"SOWP\", \"SOUT\", \"SAUT\", \"SAIS\", \"POOT\", \"WOOT\", \"LEEP\", \"TYTE\", \"GART\", \"LYMS\", \"PIES\", \"LOME\", \"TAKY\", \"OARY\", \n",
    "      \"JEAT\", \"GEAN\", \"SEAN\", \"PERN\", \"PENE\", \"MENT\", \"MENE\", \"SYEN\", \"ETEN\", \"HYEN\", \"HYED\", \"NISH\", \"SIGS\", \"SICH\", \"SUGS\",\n",
    "      \"TOSE\", \"TRON\", \"VELE\", \"VELL\", \"WEIL\", \"BHAT\", \"BOKS\", \"POLK\", \"TRIN\", \"GNOW\", \"AROW\", \"PELL\", \"PAAL\", \"BOTE\", \"NOUT\", \n",
    "      \"VERS\", \"TOUN\", \"LOUN\", \"HOON\", \"BOUN\", \"HORS\", \"HEYS\", \"YORK\", \"YOUK\", \"MOZE\", \"EECH\", \"TAIT\", \"RACH\", \"MAIK\", \"TECS\", \n",
    "      \"SECH\", \"LOSH\", \"TREM\", \"SKED\", \"EHED\", \"SYED\", \"NYED\", \"EOAN\", \"CIRL\", \"YESK\", \"DELO\", \"DESI\", \"DEEK\", \"HESP\", \"FAUT\", \n",
    "      \"LUIT\", \"TWAY\", \"TAKS\", \"AINE\", \"TIKS\", \"SERR\", \"SEIR\", \"SELE\", \"HELE\", \"SELD\", \"HEID\", \"LEIR\", \"WEID\", \"GAID\", \"LAIK\",\n",
    "      \"GOOK\", \"BRAK\", \"TOCK\", \"GRIS\", \"GANT\", \"RAIT\", \"RAIK\", \"GEIT\", \"COIT\", \"CERT\", \"CUIT\", \"WASE\", \"WAAH\", \"JURE\", \"FLOB\",\n",
    "      \"FOOS\", \"FOUD\", \"GOWF\", \"SOOP\", \"COSE\", \"LEAT\", \"FEIS\", \"TEAD\", \"BROD\", \"BROG\", \"DRAD\", \"PIOY\", \"KAIE\", \"PAIS\", \"PAAN\",\n",
    "      \"GARE\", \"POWN\", \"DOWL\", \"LEED\", \"SOUM\", \"SEIK\", \"SEIL\", \"MEES\", \"MOYS\", \"LOYS\", \"SAAG\", \"PRYS\", \"LARE\", \"MOUS\", \"FOUS\", \n",
    "      \"LOKE\", \"LOOR\", \"DOOK\", \"POOK\", \"MOOK\", \"HOOR\", \"DOUK\", \"SISS\", \"TETE\", \"HETE\", \"SIES\", \"REAK\", \"SCAW\", \"YEAD\", \"MINO\", \n",
    "      \"MENG\", \"JUDY\", \"DULE\", \"PUMY\", \"SIEN\", \"WAID\", \"LISK\", \"RISP\", \"DIMP\", \"SAIM\", \"RORT\", \"RORE\", \"AIAS\", \"BING\", \"ANNS\", \n",
    "      \"ALAP\", \"BRAP\", \"FRAS\", \"PLAP\", \"COMS\", \"VOLS\", \"NIMB\", \"GOLP\", \"LOMA\", \"HOMA\", \"BOOL\", \"RAST\", \"POSS\", \"CHIB\", \"SENS\", \n",
    "      \"TASH\", \"TAWT\", \"DOOL\", \"LIND\", \"LERE\", \"COOM\", \"CRON\", \"TUAN\", \"HERY\", \"GURN\", \"TURM\", \"BUAT\", \"HORE\", \"SAFT\", \"GOLE\", \n",
    "      \"FETT\", \"TOLT\", \"GEAL\", \"YOLD\", \"ARED\", \"GREN\", \"MARD\", \"GONS\", \"FENT\", \"ROIN\", \"LOIR\", \"RAUN\", \"FAUR\", \"COUR\", \"SNEB\", \n",
    "      \"PENK\", \"TRAT\", \"TAIG\", \"ARET\", \"DOSH\", \"CHAS\", \"CHAL\", \"SANT\", \"MOOP\", \"DOON\", \"COWP\", \"THON\", \"SHEN\", \"ABID\", \"FEEN\", \n",
    "      \"ALOD\", \"LANT\", \"CLAT\", \"WHOT\", \"PIET\", \"TOSA\", \"TOGE\", \"TEEK\", \"TREW\", \"TEER\", \"HOLO\", \"SHET\", \"BONA\", \"HOGH\", \"HISH\", \n",
    "      \"TAIS\", \"SIND\", \"RITS\", \"WAIS\", \"TAES\", \"KAIS\", \"TUMS\", \"MICH\", \"DICH\", \"ROUM\", \"DOUT\", \"ROUL\", \"DOUP\", \"DOUN\", \"SOWL\", \n",
    "      \"NOWL\", \"LEVS\", \"LOTE\"]\n",
    "for word in rem:\n",
    "    words.remove(word)\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a2d071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets all possible connecting words for a word\n",
    "def get_next_words (current_words, words):\n",
    "    next_words = []\n",
    "    for word in current_words:\n",
    "        for possible in words:\n",
    "            if (possible == word):\n",
    "                continue\n",
    "            elif (possible[1:] == word[1:]):\n",
    "                next_words.append(possible)\n",
    "            elif (possible[2:] == word[2:] and possible[:1] == word[:1]):\n",
    "                next_words.append(possible)\n",
    "            elif (possible[3:] == word[3:] and possible[:2] == word[:2]):\n",
    "                next_words.append(possible)\n",
    "            elif (possible[:3] == word[:3]):\n",
    "                next_words.append(possible)\n",
    "    return next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800d742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Records the ideal next words\n",
    "def get_word_dicts (current_words, words):\n",
    "    next_words = {}\n",
    "    for word in current_words:\n",
    "        for possible in words:\n",
    "            if (possible == word):\n",
    "                continue\n",
    "            elif (possible[1:] == word[1:]):\n",
    "                next_words[possible] = word\n",
    "            elif (possible[2:] == word[2:] and possible[:1] == word[:1]):\n",
    "                next_words[possible] = word\n",
    "            elif (possible[3:] == word[3:] and possible[:2] == word[:2]):\n",
    "                next_words[possible] = word\n",
    "            elif (possible[:3] == word[:3]):\n",
    "                next_words[possible] = word\n",
    "    return next_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6d9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates huge branches to search for ideal words (very slow)\n",
    "def naive_approach (starting_word, ending_word):\n",
    "    w = starting_word\n",
    "    flag = True\n",
    "    counter = 0\n",
    "    while (flag == True):\n",
    "        w = get_next_words(w, words)\n",
    "        w = list(dict.fromkeys(w))\n",
    "        counter += 1\n",
    "        if ending_word in w:\n",
    "            flag = False\n",
    "    \n",
    "    lists = []\n",
    "    d = get_word_dicts(starting_word, words)\n",
    "    lists.append(d)\n",
    "    for i in range (1,counter):\n",
    "        d = get_word_dicts(d.keys(), words)\n",
    "        lists.append(d)\n",
    "\n",
    "    index = counter - 1\n",
    "    temp = ending_word\n",
    "    l = []\n",
    "\n",
    "    while (index >= -1):\n",
    "        l.append(temp)\n",
    "        temp = lists[index][temp]\n",
    "        index -= 1\n",
    "\n",
    "    l.reverse()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bbdb37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Builds connected graph of words that connect\n",
    "def build_network(words):\n",
    "    G = nx.Graph()\n",
    "    for word in words:\n",
    "        G.add_node(word)\n",
    "        edges = get_next_words([word], words)\n",
    "        for edge in edges:\n",
    "            G.add_edge(word, edge)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fee01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find shortest path between word nodes\n",
    "def network_approach(G, starting_word, ending_word):\n",
    "    return nx.shortest_path(G, source=starting_word, target=ending_word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4acbdaec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.084115505218506\n"
     ]
    }
   ],
   "source": [
    "#Build a network (takes about a minute)\n",
    "stime = time.time()\n",
    "G = build_network(words)\n",
    "print(time.time() - stime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a71bc24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249.98404479026794\n",
      "0.0\n",
      "['GOAT', 'BOAT', 'BLAT', 'BLAY', 'ALAY', 'ALKY', 'ALKO', 'ALSO']\n",
      "['GOAT', 'BOAT', 'BLAT', 'BLAE', 'ALAE', 'ALOE', 'ALOO', 'ALSO']\n"
     ]
    }
   ],
   "source": [
    "#Test and time the 2 approaches\n",
    "starting_word = 'GOAT'\n",
    "ending_word = 'ALSO'\n",
    "\n",
    "stime = time.time()\n",
    "l1 = naive_approach([starting_word], ending_word)\n",
    "print(time.time() - stime)\n",
    "\n",
    "stime = time.time()\n",
    "l2 = network_approach(G, starting_word, ending_word)\n",
    "print(time.time() - stime)\n",
    "\n",
    "print(l1)\n",
    "print(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d225f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AMBO', 'AMMO', 'UMBO'}\n",
      "{'PFUI', 'ETUI', 'PTUI'}\n",
      "{'AWOL', 'AWDL'}\n",
      "{'ESKY', 'ESPY'}\n",
      "{'ISBA', 'ISNA'}\n",
      "{'ORYX', 'ONYX'}\n",
      "{'UPBY', 'UPSY'}\n",
      "{'ABRI'}\n",
      "{'ACAI'}\n",
      "{'ADAW'}\n",
      "{'ADZE'}\n",
      "{'AESC'}\n",
      "{'AHOY'}\n",
      "{'ANKH'}\n",
      "{'ASCI'}\n",
      "{'AZYM'}\n",
      "{'DJIN'}\n",
      "{'DZHO'}\n",
      "{'ECRU'}\n",
      "{'EEVN'}\n",
      "{'EKKA'}\n",
      "{'ELHI'}\n",
      "{'ENUF'}\n",
      "{'ENVY'}\n",
      "{'EPEE'}\n",
      "{'EPHA'}\n",
      "{'ERHU'}\n",
      "{'EUOI'}\n",
      "{'EVIL'}\n",
      "{'EXAM'}\n",
      "{'EXPO'}\n",
      "{'EXUL'}\n",
      "{'HMMM'}\n",
      "{'HUHU'}\n",
      "{'HWYL'}\n",
      "{'HYMN'}\n",
      "{'IMAM'}\n",
      "{'ISIT'}\n",
      "{'JEHU'}\n",
      "{'JEUX'}\n",
      "{'KHOR'}\n",
      "{'KIWI'}\n",
      "{'LWEI'}\n",
      "{'MWAH'}\n",
      "{'MYXO'}\n",
      "{'MZEE'}\n",
      "{'NGAI'}\n",
      "{'OCCY'}\n",
      "{'ODOR'}\n",
      "{'ODSO'}\n",
      "{'OGAM'}\n",
      "{'OMBU'}\n",
      "{'OMOV'}\n",
      "{'OPPO'}\n",
      "{'OSSA'}\n",
      "{'OVUM'}\n",
      "{'PFFT'}\n",
      "{'PRUH'}\n",
      "{'UGHS'}\n",
      "{'UPTA'}\n",
      "{'VULN'}\n",
      "{'WAAC'}\n",
      "{'YEBO'}\n",
      "{'YGOE'}\n",
      "{'YUNX'}\n",
      "{'ZOIC'}\n",
      "{'ZYGA'}\n",
      "{'ZZZS'}\n"
     ]
    }
   ],
   "source": [
    "#Print small isolated groups in the network (don't connect to anything else)\n",
    "for c in sorted(nx.connected_components(G), key=len, reverse=True):\n",
    "    if len(c) <= 100:\n",
    "        print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
